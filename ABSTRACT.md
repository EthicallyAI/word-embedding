There is a fundamental gap between ethics, which lays in the kingdom of human values, and artificial intelligence, which is, broadly speaking, is a mathematical model. Nowadays, many intelligent systems are being deployed daily, and data scientists are making decisions in the mathematical domain, that may have ethical and social implications.
How can practitioners embed ethics in an intelligent system? How can they audit the ethics of AI? What are the limitations of such methods?

In this one and a half hours workshop, we will explore bias in word embedding - a widespread building block of many machine learning models that work with natural languages. Word embeddings have an easy-to-explain representation that allows an intuitive understanding of this building block and its potential biases without a technical background.
We will use an open-source toolkit called [Responsibly](https://docs.responsibly.ai/) to explore, visualize, measure bias and debias word embedding, particularly the gender bias.

Word embeddings will serve as a window to the bias research in Machine Learning. Besides, the exploration process will naturally raise practical, methodological and philosophical questions about the ethics of AI and the limitation of technical measurement and mitigation approaches, which we will be discussed in the workshop.

The workshop is hands-on and interactive, where the participants will be able to run pre-written code in parallel to the instructor in the same tools that data scientists are using. Nevertheless, the workshop is designed to a diverse audience: from without any background in machine learning or programming to data science practitioners. The participants should bring their own laptops, but no setup is required.
